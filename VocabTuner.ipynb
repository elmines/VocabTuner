{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cntk as C\n",
    "import numpy as np\n",
    "\n",
    "#Import local modules\n",
    "import os\n",
    "import sys\n",
    "modulesPath = \"scripts\"\n",
    "modulesPath = os.path.abspath(os.path.join(modulesPath))\n",
    "if modulesPath not in sys.path: sys.path.append(modulesPath)\n",
    "from bicorpus import Bicorpus\n",
    "\n",
    "C.cntk_py.set_fixed_random_seed(0)\n",
    "\n",
    "#Model hyperparameters\n",
    "my_dtype = np.float32\n",
    "hidden_dim = 512\n",
    "num_layers = 2\n",
    "attention_dim = 128\n",
    "use_attention = True\n",
    "use_embedding = True\n",
    "embedding_dim = 200\n",
    "length_increase = 1.5\n",
    "\n",
    "\"\"\"\n",
    "vocabSize = 10000\n",
    "sourceVocabSize = vocabSize\n",
    "destVocabSize = vocabSize\n",
    "\"\"\"\n",
    "\n",
    "numSequences = 10000\n",
    "training_ratio = 3 / 4\n",
    "max_epochs = 1\n",
    "epoch_size = 50 #int(numSequences * training_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 sequences read.\n",
      "1000 sequences read.\n",
      "1500 sequences read.\n",
      "2000 sequences read.\n",
      "2500 sequences read.\n",
      "3000 sequences read.\n",
      "3500 sequences read.\n",
      "4000 sequences read.\n",
      "4500 sequences read.\n",
      "5000 sequences read.\n",
      "5500 sequences read.\n",
      "6000 sequences read.\n",
      "6500 sequences read.\n",
      "7000 sequences read.\n",
      "7500 sequences read.\n",
      "8000 sequences read.\n",
      "8500 sequences read.\n",
      "9000 sequences read.\n",
      "9500 sequences read.\n",
      "10000 sequences read.\n"
     ]
    }
   ],
   "source": [
    "files = {}\n",
    "\n",
    "sourceTraining = \"corpora/europarl-v7.es-en.es\"\n",
    "destTraining = \"corpora/europarl-v7.es-en.en\"\n",
    "\n",
    "\n",
    "\n",
    "with open(sourceTraining, \"r\", encoding = \"utf-8\") as sourceFile:\n",
    "    sourceLines = sourceFile.readlines()\n",
    "with open(destTraining, \"r\", encoding = \"utf-8\") as destFile:\n",
    "    destLines = destFile.readlines()\n",
    "\n",
    "trainingCorp = Bicorpus(sourceLines, destLines, numSequences = 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11113\n",
      "11113\n"
     ]
    }
   ],
   "source": [
    "cleanedSource, cleanedDest = trainingCorp.training_lines()\n",
    "sourceW2I, destW2I = trainingCorp.getW2IDicts()\n",
    "sourceI2W, destI2W = trainingCorp.getI2WDicts()\n",
    "\n",
    "#The \"+ 1\"s are for the UNK token; I will have to add that to Bicorpus later on\n",
    "sourceVocabSize, destVocabSize = len(sourceW2I) + 1, len(destW2I) + 1\n",
    "\n",
    "seq_start_index = destW2I[Bicorpus.start_token()]\n",
    "seq_end_index = destW2I[Bicorpus.end_token()]\n",
    "#seq_start = C.constant(np.asarray([i == seq_start_index for i in range(len(destW2I))], dtype = my_dtype))\n",
    "seq_start = C.constant(np.asarray([i == seq_start_index for i in range(destVocabSize)], dtype = my_dtype))\n",
    "\n",
    "\n",
    "print(sourceVocabSize)\n",
    "print(destVocabSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Source and target inputs to the model\n",
    "sourceAxis = C.Axis(\"sourceAxis\")\n",
    "destAxis = C.Axis(\"destAxis\")\n",
    "sourceSequence = C.layers.SequenceOver[sourceAxis]\n",
    "destSequence = C.layers.SequenceOver[destAxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Returns a general sequence-to-sequence model\n",
    "def create_model():\n",
    "    embed = C.layers.Embedding(embedding_dim, name = \"embed\") if use_embedding else identity #Where is \"identity defined?\n",
    "    \n",
    "    with C.layers.default_options(enable_self_stabilization = True, go_backwards = not use_attention):\n",
    "        LastRecurrence = C.layers.Fold if not use_attention else C.layers.Recurrence\n",
    "        encode = C.layers.Sequential([\n",
    "            embed,\n",
    "            C.layers.Stabilizer(),\n",
    "            C.layers.For(range(num_layers - 1), lambda: C.layers.Recurrence(C.layers.GRU(hidden_dim))),\n",
    "            LastRecurrence(C.layers.GRU(hidden_dim), return_full_state = True),\n",
    "            C.layers.Label(\"encoded_h\")                                  \n",
    "        ])\n",
    "    \n",
    "    with C.layers.default_options(enable_self_stabilization = True):\n",
    "        stab_in = C.layers.Stabilizer()\n",
    "        rec_blocks = [C.layers.GRU(hidden_dim) for i in range(num_layers)]\n",
    "        stab_out = C.layers.Stabilizer()\n",
    "        proj_out = C.layers.Dense(destVocabSize, name = \"out_proj\")\n",
    "        if use_attention:\n",
    "            attention_model = C.layers.AttentionModel(attention_dim, name = \"attention_model\")\n",
    "            \n",
    "        @C.Function\n",
    "        def decode(history, input):\n",
    "            encoded_input = encode(input)\n",
    "            r = history\n",
    "            r = embed(r)\n",
    "            r = stab_in(r)\n",
    "            for i in range(num_layers):\n",
    "                rec_block = rec_blocks[i]\n",
    "                if i == 0:\n",
    "                    if use_attention:\n",
    "                        @C.Function\n",
    "                        def gru_with_attention(dh, x):\n",
    "                            h_att = attention_model(encoded_input.outputs[0], dh)\n",
    "                            x = C.splice(x, h_att)\n",
    "                            toReturn = rec_block(dh, x)\n",
    "                            return toReturn\n",
    "                        r = C.layers.Recurrence(gru_with_attention)(r)\n",
    "                        \n",
    "                    else:\n",
    "                        r = C.layers.Recurrence(rec_block)(r)\n",
    "                else:\n",
    "                    r = C.layers.RecurrenceFrom(rec_block)( *(encoded_input.outputs + (r,)) )\n",
    "            r = stab_out(r)\n",
    "            r = proj_out(r)\n",
    "            r = C.layers.Label(\"out_proj_out\")(r)\n",
    "            return r\n",
    "                \n",
    "        return decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model_train(s2smodel):\n",
    "    @C.Function\n",
    "    def model_train(input, labels):\n",
    "        past_labels = C.layers.Delay(initial_state = seq_start)(labels)\n",
    "        return s2smodel(past_labels, input)\n",
    "    return model_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Model used in testing\n",
    "def create_model_greedy(s2smodel):\n",
    "    @C.Function\n",
    "    @C.layers.Signature(sourceSequence[C.layers.Tensor[sourceVocabSize]])\n",
    "    def model_greedy(input):\n",
    "        unfold = C.layers.UnfoldFrom(lambda history: s2smodel(history, input) >> C.hardmax,\n",
    "                                    until_predicate = lambda w: w[..., seq_end_index],\n",
    "                                    length_increase = length_increase)\n",
    "        return unfold(initial_state = seq_start, dynamic_axes_like = input)\n",
    "    return model_greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_criterion_function(model):\n",
    "    @C.Function\n",
    "    @C.layers.Signature(input=sourceSequence[C.layers.Tensor[sourceVocabSize]],\n",
    "                        labels=destSequence[C.layers.Tensor[destVocabSize]]) #Should also be \"sourceVocabSize?\"\n",
    "    def criterion(input, labels):\n",
    "        # criterion function must drop the <s> from the labels\n",
    "        postprocessed_labels = C.sequence.slice(labels, 1, 0) # <s> A B C </s> --> A B C </s>\n",
    "        #print(\"input =\", input)\n",
    "        #print(\"postprocessed_labels =\", postprocessed_labels)\n",
    "        z = model(input, postprocessed_labels)\n",
    "        #print(\"z =\", z)\n",
    "        ce = C.cross_entropy_with_softmax(z, postprocessed_labels) #labels)\n",
    "        errs = C.classification_error(z, postprocessed_labels) #labels)\n",
    "        return (ce, errs)\n",
    "\n",
    "    return criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_sequences(sequences, i2w):\n",
    "    return [\" \".join([i2w[np.argmax(w)] for w in s]) for s in sequences]\n",
    "\n",
    "def debug_attention(model, input):\n",
    "    q = C.combine([model, model.attention_model.attention_weights])\n",
    "    #words, p = q(input) # Python 3\n",
    "    words_p = q(input)\n",
    "    words = words_p[0]\n",
    "    p     = words_p[1]\n",
    "    output_seq_len = words[0].shape[0]\n",
    "    p_sq = np.squeeze(p[0][:output_seq_len,:,:]) # (batch, output_len, input_len, 1)\n",
    "    opts = np.get_printoptions()\n",
    "    np.set_printoptions(precision=5)\n",
    "    print(p_sq)\n",
    "    np.set_printoptions(**opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wordToOneHot(word, w2i):\n",
    "    #The \"plus 1\" is for the <UNK> token\n",
    "    vector = np.zeros(len(w2i) + 1, dtype = my_dtype)\n",
    "    try:\n",
    "        vector[w2i[word]] = 1\n",
    "    except KeyError:\n",
    "        vector[len(w2i)] = 1 #The one-hot vector for the <UNK> token\n",
    "    return vector\n",
    "\n",
    "def wordsToIndices(wordList, w2i):\n",
    "    if type(wordList) == str: wordList = wordList.split(\" \")\n",
    "    indices = []\n",
    "    for word in wordList:\n",
    "        try:\n",
    "            indices.append(w2i[word])\n",
    "        except KeyError:\n",
    "            indices.append(len(w2i)) #The one-hot vector for the <UNK> token\n",
    "    return indices\n",
    "\n",
    "def wordsToOneHot(wordList, w2i):\n",
    "    if type(wordList) == str: wordList = wordList.split(\" \")\n",
    "    return np.stack([wordToOneHot(word, w2i) for word in wordList])\n",
    "\n",
    "def sequencesToOneHot(sequences, w2i):\n",
    "    return [wordsToOneHot(sequence, w2i) for sequence in sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The original had \"vocab\" as a parameter but never used it\n",
    "#The original had CTF readers train_reader and validation_reader\n",
    "def train(sourceW2I, destW2I, s2smodel, max_epochs, epoch_size):\n",
    "    model_train = create_model_train(s2smodel)\n",
    "    criterion = create_criterion_function(model_train)\n",
    "    #model_greedy = create_model_greedy(s2smodel)\n",
    "    \n",
    "    minibatch_size = 50\n",
    "    lr = 0.001 if use_attention else 0.005\n",
    "    learner = C.fsadagrad(model_train.parameters,\n",
    "                         lr = C.learning_rate_schedule([lr]*2 + [lr/2]*3 +[lr/4], C.UnitType.sample, epoch_size),\n",
    "                         momentum = C.momentum_as_time_constant_schedule(1100),\n",
    "                         gradient_clipping_threshold_per_sample = 2.3,\n",
    "                         gradient_clipping_with_truncation = True)\n",
    "    trainer = C.Trainer(None, criterion, learner)                      #\n",
    "    \n",
    "    total_samples = 0\n",
    "    mbs = 0\n",
    "    eval_freq = 100\n",
    "    \n",
    "    C.logging.log_number_of_parameters(model_train) ; print()\n",
    "    progress_printer = C.logging.ProgressPrinter(freq = 30, tag = \"Training\")\n",
    "    \n",
    "    #sparse_to_dense = create_sparse_to_dense(sourceVocabSize)\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        mb_num = 0\n",
    "        while total_samples < (epoch + 1) * epoch_size:\n",
    "            #print(\"total_samples =\", total_samples)\n",
    "            #print(\"mbs =\", mbs)\n",
    "            startIndex = mbs * minibatch_size\n",
    "            endIndex = startIndex + minibatch_size\n",
    "            \n",
    "            \"\"\"\n",
    "            mb_train = train_reader.next_minibatch(minibatch_size)\n",
    "            trainer.train_minibatch({criterion.arguments[0]: mb_train[train_reader.streams.features],\n",
    "                                     criterion.arguments[1]: mb_train[train_reader.streams.labels]})\n",
    "            \"\"\"\n",
    "            \n",
    "            sourceBatch = sequencesToOneHot(cleanedSource[startIndex:endIndex], sourceW2I)\n",
    "            destBatch = sequencesToOneHot(cleanedDest[startIndex:endIndex], destW2I)\n",
    "            trainer.train_minibatch({criterion.arguments[0]: sourceBatch,\n",
    "                                     criterion.arguments[1]: destBatch\n",
    "                                    })\n",
    "            \n",
    "            \n",
    "            \n",
    "            progress_printer.update_with_trainer(trainer, with_metric = True)\n",
    "            \n",
    "            \"\"\"\n",
    "            if mbs % eval_freq == 0:\n",
    "                mb_valid = valid_reader.next_minibatch(1)\n",
    "                e = model_greedy(mb_valid[valid_reader.streams.features])\n",
    "                \n",
    "                #Need to i2w to my own dictionary\n",
    "                #Really, I just need to add a function to my Bicorpus class\n",
    "                print(format_sequence(sparse_to_dense(mb_valid[valid_reader.streams.features]), sourceI2W))\n",
    "                print(\"-->\")\n",
    "                print(format_sequences(e, destI2W))\n",
    "                \n",
    "                if use_attention:\n",
    "                    debug_attention(model_greedy, mb_valid[valid_reader.streams.features])\n",
    "            \"\"\"\n",
    "                    \n",
    "            total_samples += minibatch_size #mb.train[train_reader.streams.labels].num_samples\n",
    "            mbs += 1\n",
    "                \n",
    "    progress_printer.epoch_summary(with_metric = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 14180348 parameters in 33 parameter tensors.\n",
      "\n",
      "Finished Epoch[1]: [Training] loss = 9.315683 * 1210, metric = 100.00% * 1210 11.355s (106.6 samples/s);\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "train(sourceI2W, destI2W, model, max_epochs, epoch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "def translate(text, model, sourceW2I, destI2W):\n",
    "    #vectors = wordsToOneHot(text, sourceW2I)\n",
    "    \n",
    "    \n",
    "    indices = wordsToIndices(text, sourceW2I)\n",
    "    indices.insert(0, sourceW2I[Bicorpus.start_token()])\n",
    "    indices.append(sourceW2I[Bicorpus.end_token()])\n",
    "    \n",
    "    query = C.Value.one_hot([indices], len(sourceW2I) + 1)\n",
    "    \n",
    "    print(inspect.signature(model))\n",
    "    \n",
    "    pred = model(query)\n",
    "    pred = pred[0] # first sequence (we only have one) -> [len, vocab size]\n",
    "    if use_attention:\n",
    "        pred = np.squeeze(pred) # attention has extra dimensions\n",
    "\n",
    "    # print out translation and stop at the sequence-end tag\n",
    "    prediction = np.argmax(pred, axis=-1)\n",
    "    #translation = [destI2W[i] for i in prediction]\n",
    "    \n",
    "    #print(translation)\n",
    "    for i in prediction:\n",
    "        print(destI2W[i])\n",
    "    \n",
    "    \n",
    "\n",
    "def debugging(trained_model):\n",
    "    model = create_model_greedy(trained_model)\n",
    "    \n",
    "    query = input(\"Enter a Spanish phrase (or just <Enter> to quit): \").strip()\n",
    "    while query:\n",
    "        translate(query, trained_model, sourceW2I, destI2W)\n",
    "        query = input(\"Enter a Spanish phrase (or just <Enter> to quit): \").strip()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a Spanish phrase (or just <Enter> to quit): ella es\n",
      "(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "CNTK Function expected 2 arguments, got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-be500bd04f55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdebugging\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-aa9d92ce91db>\u001b[0m in \u001b[0;36mdebugging\u001b[1;34m(trained_model)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Enter a Spanish phrase (or just <Enter> to quit): \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrained_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msourceW2I\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestI2W\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Enter a Spanish phrase (or just <Enter> to quit): \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-aa9d92ce91db>\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(text, model, sourceW2I, destI2W)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# first sequence (we only have one) -> [len, vocab size]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muse_attention\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ethan Mines\\Anaconda3\\lib\\site-packages\\cntk\\ops\\functions.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m         \u001b[1;31m# parse argument list and map to the function's input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m         \u001b[0marg_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margument_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[1;31m# if placeholders were excluded due to being under construction,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ethan Mines\\Anaconda3\\lib\\site-packages\\cntk\\ops\\functions.py\u001b[0m in \u001b[0;36margument_map\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m    \u001b[1;31m# function parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CNTK Function expected {} arguments, got {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m         \u001b[0mparams_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmap_function_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: CNTK Function expected 2 arguments, got 1"
     ]
    }
   ],
   "source": [
    "debugging(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*args, **kwargs)\n",
      "OrderedDict([('args', <Parameter \"*args\">), ('kwargs', <Parameter \"**kwargs\">)])\n"
     ]
    }
   ],
   "source": [
    "sig = inspect.signature(create_model_greedy(model))\n",
    "print(sig)\n",
    "\n",
    "parameters = sig.parameters\n",
    "print(parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
